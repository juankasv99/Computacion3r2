{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducció a la pràctica 2: primers passos\n",
    "\n",
    "## Objectius\n",
    "\n",
    "Els objectius d'aquesta pràctica són:\n",
    "  \n",
    "* Aplicar models de classificació, ficant l'èmfasi en:\n",
    "    1. Aplicar diferents classificadors (regressor logístic i svm) i entendre les millores d'aplicar kernels.\n",
    "    2. Avaluar correctament l'error del model \n",
    "    3. Visualitzar les dades i el model resultant\n",
    "\n",
    "\n",
    "* Ésser capaç d'aplicar tècniques de classificació en casos reals\n",
    "\n",
    "* Validar els resultats en dades reals\n",
    "\n",
    "* Fomentar la capacitat per presentar resultats tècnics d'aprenentatge computacional de forma adequada davant altres persones\n",
    "\n",
    "\n",
    "## Bases de dades\n",
    "\n",
    "Cada grup utilitzarà les bases de dades que se li hagin assignat depenent del grup on s'ha apuntat al caronte. \n",
    "\n",
    "\n",
    "| # | GRUP | BASE DE DADES APARTAT B | BASE DE DADES APARTAT A |\n",
    "|:-:|:-:|:--|:--|\n",
    "|\t1\t|\tGA\\*01-0000\t| https://www.kaggle.com/rounakbanik/pokemon\t| https://www.kaggle.com/mlg-ulb/creditcardfraud (anomaly)|\n",
    "|\t2\t|\tGA\\*02-0000\t| https://www.kaggle.com/uciml/zoo-animal-classification\t| https://www.kaggle.com/aaron7sun/stocknews (nlp)|\n",
    "|\t3\t|\tGA\\*03-0000\t| https://www.kaggle.com/jsphyg/weather-dataset-rattle-package\t|\thttps://www.kaggle.com/kmader/food41 (images)|\n",
    "|\t4\t|\tGA\\*04-0000\t|https://www.kaggle.com/iabhishekofficial/mobile-price-classification\t|\thttps://www.kaggle.com/snap/amazon-fine-food-reviews (reviews)|\n",
    "|\t5\t|\tGA\\*05-0000\t|https://www.kaggle.com/kyr7plus/emg-4\t|\thttps://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification (audio)|\n",
    "|\t6\t|\tGA\\*06-0000\t|https://www.kaggle.com/uciml/glass\t|\thttps://www.kaggle.com/watesoyan/omniglot (few-shot)|\n",
    "|\t7\t|\tGA\\*07-0000\t|https://www.kaggle.com/c/titanic/data\t|\thttps://www.kaggle.com/birdy654/scene-classification-images-and-audio (multimodal) |\n",
    "|\t8\t|\tGA\\*08-0000\t|https://www.kaggle.com/elikplim/car-evaluation-data-set\t|\thttps://www.kaggle.com/paultimothymooney/chest-xray-pneumonia (medical) |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Avaluació i entregues de la pràctica 2\n",
    "\n",
    "En la pràctica 2, es presenten diversos problemes per comprendre els mètodes de classificació numèrica.\n",
    "\n",
    "Les entregues s'organitzen en dos nivells d'assoliment dels objectius, incrementals: apartat **B, (sobre 6 punts)**, assoliment baix; apartat **A, (sobre 4 punts)**, assoliment alt. La suma dels 2 apartats serà la nota final de la pràctica 2. Per a realitzar el apartat A, prèviament s'ha d'haver presentat el apartat B.\n",
    "\n",
    "Per cada apartat s'utilitzarà una base de dades diferent. A l'apartat B, treballarem majoritariament amb dades numèriques i es farà servir per establir les bases i l'esquelet per l'apartat A, on hi trobarem unes dades molt més riques i complexes.\n",
    "\n",
    "\n",
    "### Sessió de control apartat (B), Classificació Numèrica (6pts)\n",
    "\n",
    "Similarment a la sessió de informativa de la pràctica 1, l'assistència i la participació serà opcional, però igualment molt recomenat que s'entregui una presentació que presenti les bases de dades asignades i els problemes que heu de resoldre, per si hi haguéssin problemes amb la base de dades, les preguntes, els metodes a aplicar..\n",
    "\n",
    "Així, aquesta sessió està orientada a que, els alumnes que vingueu pugueu preguntar i resoldre dubtes sobre les bases de dades que us han estat assignades, preguntar sobre l'objectiu de cada apartat dels enunciats que no us hagi quedat clar, i preguntar sobre els resultats que esteu obtenint a l'hora d'analitzar les dades.\n",
    "\n",
    "Les presentacions en les sessions de control es faran davant de tota la classe, d'un màxim de 5 minuts. Es recomana:\n",
    "* una primera slide describint les bases de dades, \n",
    "* una altra amb els atributs més importants, \n",
    "* una tercera resumint el que s'ha provat, \n",
    "* una altra amb les conclusions que s'hagin tret, \n",
    "* i una última amb els problemes que us hàgiu trobat i quina solució proposeu, o si ja els heu solucionat, com ho vau solucionar per ajudar als vostres companys.\n",
    "\n",
    "### Sessió d'avaluació apartat (A), Classificació Avançada (4pts)\n",
    "\n",
    "En la següent sessió del 26 de novembre s'evaluarà la **pràctica sencera amb els dos apartats**. Caldrà pujar al Caronte abans de les 00:59 del dilluns 23 de novembre un ZIP amb el codi, la documentació i el ppt (10 minuts) de l'apartat (A) sobre classificació. Podeu \"recuperar\" l'apartat (B) entregant-ho per aquesta sessió, ja que aprovar la pràctica és obligatori fer l'apartat (B).\n",
    "\n",
    "\n",
    "### Dates Importants de la pràctica\n",
    "\n",
    "La data máxima d'entrega ZIP de tots els apartats és a la una de la matinada dels dilluns anteriors a aquestes sessions, és a dir, una hora després de diumenge a les 23:59.\n",
    "\n",
    "Assistència voluntària:\n",
    "\n",
    "* **02/11** sessió d'introducció i explicació de la pràctica\n",
    "* **12/11** sessió de control: Entendre BBDD asignades i resoldre dubtes..\n",
    " * Entrega ZIP (abans de 00:59 del dilluns 9 de novembre 00:59):\n",
    "  * Presentació de 5 minuts màxim\n",
    "\n",
    "Assistència obligatoria:\n",
    "\n",
    "* **26/11** sessió d'avaluació: \n",
    " * Entrega ZIP (abans de 00:59 del dilluns 23 de novembre 00:59)\n",
    "   * Apartat B. (6pts)\n",
    "     1. Memòria explicant els resultats trobats sobre la base de dades B que heu treballat (10-50 pàgs). (4pts)\n",
    "     2. Codi python desenvolupat. (1.5pts)\n",
    "     3. Presentació amb els resultats 4 min màxim. (0.5pts)\n",
    "   * Apartat A. (4pts)\n",
    "     1. Memòria en format article mostrant els experiments realitzats sobre les dades de A (4-8 pàgs). (2pts) \n",
    "     2. Codi python desenvolupat. (0.5pts)\n",
    "     3. Presentació amb els resultats 6 min màxim. (1pt)\n",
    "     4. Pòster. (0.5pt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Dataset. Exemples de codi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import some data to play with\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Take the first two features. We could avoid this by using a two-dim dataset\n",
    "X = iris.data[:, :2]\n",
    "y = iris.target\n",
    "\n",
    "n_classes = 3\n",
    "    \n",
    "fig, sub = plt.subplots(1, 2, figsize=(16,6))\n",
    "sub[0].scatter(X[:,0], y, c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "sub[1].scatter(X[:,1], y, c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "\n",
    "\n",
    "particions = [0.5, 0.7, 0.8]\n",
    "\n",
    "for part in particions:\n",
    "    x_t, x_v, y_t, y_v = train_test_split(X, y, train_size=part)\n",
    "    \n",
    "    #Creem el regresor logístic\n",
    "    logireg = LogisticRegression(C=2.0, fit_intercept=True, penalty='l2', tol=0.001)\n",
    "\n",
    "    # l'entrenem\n",
    "    logireg.fit(x_t, y_t)\n",
    "\n",
    "    print (\"Correct classification Logistic \", part, \"% of the data: \", logireg.score(x_v, y_v))\n",
    "    \n",
    "    #Creem el regresor logístic\n",
    "    svc = svm.SVC(C=10.0, kernel='rbf', gamma=0.9, probability=True)\n",
    "\n",
    "    # l'entrenem \n",
    "    svc.fit(x_t, y_t)\n",
    "    probs = svc.predict_proba(x_v)\n",
    "    print (\"Correct classification SVM      \", part, \"% of the data: \", svc.score(x_v, y_v))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tal com podeu llegir a [l'API de sklearn](http://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html), en comptes de fer una corba per cada classe, podem considerar totes les classes en conjunt en una sola corba (1 si hem predit la classe correcta, 0 si no). Això es coneix com a `micro-averaging`. \n",
    "\n",
    "Així, veureu que la funció `f1_score` utilitza el paràmetre `macro` per calcular la precision-recall-f1 per clase, i després fer la mitja pr a totes les classes; i `micro` per utilitzar totes les prediccions (i errors de FN, FP) per a calcular una única precision-recall-f1 per a totes les classes juntes.\n",
    "\n",
    "Si voleu calcular la corba Precision-Recall quan utilitzeu el K-fold, cal calcular les corbes per a cada fold i després [fer la mitja de tots els folds per obtenir la corba final](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py). En el cas del LOOCV no té sentit fer la mitja la corba PR perquè hauriem de fer servir totes les mostres com a $y$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "\n",
    "# Compute Precision-Recall and plot curve\n",
    "precision = {}\n",
    "recall = {}\n",
    "average_precision = {}\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_v == i, probs[:, i])\n",
    "    average_precision[i] = average_precision_score(y_v == i, probs[:, i])\n",
    "\n",
    "    plt.plot(recall[i], precision[i],\n",
    "    label='Precision-recall curve of class {0} (area = {1:0.2f})'\n",
    "                           ''.format(i, average_precision[i]))\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "\n",
    "    \n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_v == i, probs[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve of class {0} (area = {1:0.2f})' ''.format(i, roc_auc[i]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def make_meshgrid(x, y, h=.02):\n",
    "    \"\"\"Create a mesh of points to plot in\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: data to base x-axis meshgrid on\n",
    "    y: data to base y-axis meshgrid on\n",
    "    h: stepsize for meshgrid, optional\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xx, yy : ndarray\n",
    "    \"\"\"\n",
    "    x_min, x_max = x.min() - 1, x.max() + 1\n",
    "    y_min, y_max = y.min() - 1, y.max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    return xx, yy\n",
    "\n",
    "\n",
    "def plot_contours(ax, clf, xx, yy, **params):\n",
    "    \"\"\"Plot the decision boundaries for a classifier.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ax: matplotlib axes object\n",
    "    clf: a classifier\n",
    "    xx: meshgrid ndarray\n",
    "    yy: meshgrid ndarray\n",
    "    params: dictionary of params to pass to contourf, optional\n",
    "    \"\"\"\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    out = ax.contourf(xx, yy, Z, **params)\n",
    "    return out\n",
    "\n",
    "def show_C_effect(C=1.0, gamma=0.7, degree=3):\n",
    "\n",
    "    # import some data to play with\n",
    "    iris = datasets.load_iris()\n",
    "    # Take the first two features. We could avoid this by using a two-dim dataset\n",
    "    X = iris.data[:, :2]\n",
    "    y = iris.target\n",
    "\n",
    "    # we create an instance of SVM and fit out data. We do not scale our\n",
    "    # data since we want to plot the support vectors\n",
    "    # title for the plots\n",
    "    titles = ('SVC with linear kernel',\n",
    "              'LinearSVC (linear kernel)',\n",
    "              'SVC with RBF kernel',\n",
    "              'SVC with polynomial (degree 3) kernel')\n",
    "\n",
    "    #C = 1.0  # SVM regularization parameter\n",
    "    models = (svm.SVC(kernel='linear', C=C),\n",
    "              svm.LinearSVC(C=C, max_iter=1000000),\n",
    "              svm.SVC(kernel='rbf', gamma=gamma, C=C),\n",
    "              svm.SVC(kernel='poly', degree=degree, gamma='auto', C=C))\n",
    "    models = (clf.fit(X, y) for clf in models)\n",
    "\n",
    "    plt.close('all')\n",
    "    fig, sub = plt.subplots(2, 2, figsize=(14,9))\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "\n",
    "    X0, X1 = X[:, 0], X[:, 1]\n",
    "    xx, yy = make_meshgrid(X0, X1)\n",
    "\n",
    "    for clf, title, ax in zip(models, titles, sub.flatten()):\n",
    "        plot_contours(ax, clf, xx, yy,\n",
    "                      cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "        ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "        ax.set_xlim(xx.min(), xx.max())\n",
    "        ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xlabel('Sepal length')\n",
    "        ax.set_ylabel('Sepal width')\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(title)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podeu provar quin efecte té diferents valors de regularització per aquest petit exemple ( C=0.0001 to 1000..). També podeu veure com afecta els valors de degree i gamma. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_C_effect(C=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sessió de control Pràctica 2: apartat (B) Classificació Numèrica (6pts)\n",
    "\n",
    "Per a aquest primer apartat, s'analitzarà els tipus d'atributs que es tenen i, si no està estipulat, **caldrà fixar quin és l'atribut objectiu a classificar de tots els que hi ha a la base de dades**.\n",
    "Expliqueu a la memòria quin atribut heu fet servir, no hi ha una decisió única correcta, cal que doneu raons de per què heu triat l'atribut que hàgiu triat.\n",
    "\n",
    "Treballarem varis aspectes de la classificació:\n",
    "\n",
    "1. EDA (exploratory data analysis)\n",
    "2. Preprocessing (normalitzation, outlier removal, feature selection..)\n",
    "3. Model Selection\n",
    "4. Crossvalidation\n",
    "5. Metric Analysis\n",
    "6. Hyperparameter Search\n",
    "\n",
    "\n",
    "Durant els següents apartats, es recomana anar fent una taula amb el mètode, paràmetres i precisió obtinguda. D'aquesta manera serà més fàcil entendre i valorar què s'aconsegueix en cada metode. Exemple:\n",
    "\n",
    "<img src=\"images/table_1.png\" width=\"80%\">\n",
    "\n",
    "Les preguntes de cada apartat són orientatives. **NO** cal contestar-les totes, ni totes tindrán sentit per tots els datasets. Són una guia per a que reflexioneu i aprengueu detalls de cada apartat. Tot i no ser obligatories, si que són molt recomenades d'intentar respondre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. EDA (exploratory data analysis)\n",
    "\n",
    "Igual com a la pràctica anterior, exploreu i visualitzeu com és la base de dades que teniu assignada.\n",
    "\n",
    "**Preguntes:**\n",
    "* Quants atributs té la vostra base de dades?\n",
    "* Quin tipus d'atributs tens? (Númerics, temporals, categorics, binaris...)\n",
    "* Com es el target, quantes categories diferents existeixen?\n",
    "* Podeu veure alguna correlació entre X i y?\n",
    "* Estan balancejades les etiquetes (distribució similar entre categories)? Creus que pot afectar a la classificació la seva distribució?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing (normalitzation, outlier removal, feature selection..)\n",
    "Un cop vistes les dades de les que es disposa, per tal de tenir un aprenentatge més eficient, es recomana normalitzar les dades i treure outliers. Segons la tipologia de dades, es poden filtrar atributs, aplicar-hi reductors de dimensionalitat, codificar categories textuals en valors numèrics..\n",
    "\n",
    "Navegueu per la [documentació de sklearn sobre preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html) per tal de trobar les diferents opcions que proporciona sklearn.\n",
    "\n",
    "**Preguntes:**\n",
    "* Estàn les dades normalitzades? Caldria fer-ho?\n",
    "* En cas que les normalitzeu, quin tipus de normalització será més adient per les vostres dades?\n",
    "* Teniu gaires dades sense informació? Els NaNs a pandas? Tingueu en compte que hi ha metodes que no els toleren durant el aprenentatge. Com afecta a la classificació si les filtrem? I si les reompliu? Com ho farieu? [Pista](https://scikit-learn.org/stable/modules/impute.html)\n",
    "* Teniu dades categoriques? Quina seria la codificació amb més sentit? (`OrdinalEncoder`, `OneHotEncoder`, d'altres?)\n",
    "* Caldria aplicar `sklearn.decomposition.PCA`? Quins beneficis o inconvenients trobarieu?\n",
    "* Es poden aplicar `PolynomialFeatures` per millorar la classificació? En quins casos té sentit fer-ho?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Selection\n",
    "La tasca d'aquesta pràctica s'enmarca dins l'aprenentatge computacional **supervisat**. A sklearn, disposem de varies tècniques [(veure documentació)](https://scikit-learn.org/stable/supervised_learning.html). A les classes de teoria, hem vist varies tècniques, com ara logistic regression, SVM amb diferents kernels, Nearest Neighbour, i el perceptró...\n",
    "En aquesta secció heu de valorar quina o quines tècniques voleu fer servir, aixi com també explicar el per què les heu seleccionat. Recomanem, que per entendre millor la teoria, s'ha de provar com a mínim un model de SVM.\n",
    "\n",
    "**Preguntes:**\n",
    "* Quins models heu considerat?\n",
    "* Considereu les SVM amb els diferents kernels implementats.\n",
    "* Quin creieu que serà el més precís?\n",
    "* Quin serà el més ràpid?\n",
    "* Seria una bona idea fer un `ensemble`? Quins inconvenients creieu que pot haver-hi? [Documentació](https://scikit-learn.org/stable/modules/ensemble.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Crossvalidation\n",
    "Un cop seleccionats quins models es volen testejar sobre les dades, s'han de poder evaluar correctament. Per aquests motius, haurem d'aprendre a cros-validar els resultats.\n",
    "Reviseu la [documentació](https://scikit-learn.org/stable/modules/cross_validation.html) i escolliu quin tipus de crossvalidació pot ser l'adecuada pel vostre problema.\n",
    "\n",
    "**Preguntes:**\n",
    "* Per què és important cross-validar els resultats?\n",
    "* Separa la base de dades en el conjunt de train-test. Com de fiables serán els resultats obtinguts? En quins casos serà més fiable, si tenim moltes dades d'entrenament o poques?\n",
    "* Quin tipus de K-fold heu escollit? Quants conjunts heu seleccionat (quina k)? Com afecta els diferents valors de k?\n",
    "* Es viable o convenient aplicar `LeaveOneOut`?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Metric Analysis\n",
    "En aquest apartat ens centrarem en les mètriques de classificació ([documentació](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)).\n",
    "\n",
    "**Preguntes:**\n",
    "* A teoria, hem vist el resultat d'aplicar el `accuracy_score` sobre dades no balancejades. Podrieu explicar i justificar quina de les següents mètriques será la més adient pel vostre problema? `accuracy_score`, `f1_score` o `average_precision_score`.\n",
    "* Mostreu la Precisió-Recall Curve i la ROC Curve. Quina és més rellevant pel vostre dataset? Expliqueu amb les vostres paraules, la diferencia entre una i altre [Pista](https://stats.stackexchange.com/questions/338826/auprc-vs-auc-roc)\n",
    "* Què mostra [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)? Quina métrica us fixareu per tal de optimitzar-ne la classificació pel vostre cas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Hyperparameter Search\n",
    "El motiu d'aplicar crossvalidació durant l'entrenament és que ens permet conèixer quin serà el resultat esperat del nostre model un cop en producció, és a dir, com es comportarà sobre dades mai vistes abans.\n",
    "A més, també ens permet optimitzar quins són els hiperparametres dels models que millor funcionaran en el futur test.\n",
    "\n",
    "**Preguntes:**\n",
    "* Quines formes de buscar el millor parametre heu trobat? Són costoses computacionalment parlant? [documentació](https://scikit-learn.org/stable/modules/grid_search.html)\n",
    "* Si disposem de recursos limitats (per exemple, un PC durant 1 hora) quin dels dos métodes creieu que obtindrà millor resultat final?\n",
    "* Existeixen altres mètodes de búsqueda més eficients ([scikit-optimize](https://scikit-optimize.github.io/stable/))?\n",
    "* Feu la prova, i amb el model i el metode de crossvalidació escollit, configureu els diferents metodes de búsqueda per a que s'executin durant el mateix temps (i.e. depenent del problema, 0,5h-1 hora). Analitzeu quin ha arribat a una millor solució. (estimeu el temps que trigarà a fer 1 training, i aixi trobeu el número de intents que podeu fer en cada cas.)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sessió d'avaluació Pràctica 2: apartat (A) Classificació Avançada (4 pts)\n",
    "\n",
    "Per aquest apartat (A), hem decidit que aprengueu a aplicar els mètodes apresos a teoria sobre bases de dades d'una mida més realista. A més, cada dataset tractarà sobre una temàtica diferent, així que podreu aprendre tècniques de diferents àmbits en escoltar i parlar amb els vostres companys.\n",
    "\n",
    "La idea és que, desde zero, sigueu capaços d'entendre el problema, tractar les dades i analitzar-les correctament. D'aquesta manera, haureu de aplicar la metodologia apresa per tal d'aprendre un model computacional que sigui capaç de predir i classificar de la millor manera possible el conjunt de test. **No cal treure resultat estat del art**, primer per què la càrrega de feina asociada a la tasca es molt inferior al temps necessàri per aconseguir-ho, i segón, per què no teniu ni l'experiència en el sector especific ni els recursos de càlcul requerits. Tot i així, el que si que us demanem, és que sigueu **rigorosos** en la vostra evaluació i què entengueu el que esteu fent.\n",
    "\n",
    "Per això, se us demana que el report d'aquesta secció segueixi els seguents subapartats (entre 4-8 pàgs.):\n",
    "1. Introduccio (A la base de dades, EDA..)\n",
    "2. Estat de l'art (explicar què han fet d'altres sobre aquestes dades o similars)\n",
    "3. Metode Utilitzat (Preprocessat, Selecció de Model..)\n",
    "4. Experiments (Crossvalidacions, hiperparaments, proves realitzades, estudi del efecte de certs parametres..)\n",
    "5. Conclusions (Què heu après i què us ha sorprès)\n",
    "6. Future work (Amb el que sabeu ara, que farieu diferent, què creieu que podria fer per millorar-ho amb més temps i que no farieu)\n",
    "\n",
    "A més, us demanem que creeu un poster de mida A0 que resumeixi el que heu fet.  Us servirà per sintetitzar i donar valor al més destacat del que heu fet. No s'haurà d'imprimir, sino que només enviar el pdf resultant.\n",
    "\n",
    "En els següents links, teniu exemples de projectes similars fets per estudiants a Stanford.\n",
    "\n",
    "* http://cs229.stanford.edu/projects2015.html\n",
    "\n",
    "* http://cs229.stanford.edu/projects2016.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
